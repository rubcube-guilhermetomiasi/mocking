{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constantes: tamanho do Mock e instância do Faker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "USER_COUNT = 118758\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções usadas ao longo do Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerar dia válido dentro de um determinado mês. Prioriza primeiros dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import calendar\n",
    "from scipy.stats import expon\n",
    "\n",
    "def generate_days(\n",
    "        month: tuple[int, int],\n",
    "        size: int,\n",
    "        start_day: int=1\n",
    "    ) -> np.ndarray | None:\n",
    "    _, last_day = calendar.monthrange(*month)\n",
    "    if start_day == last_day:\n",
    "        return np.full((size,), start_day)\n",
    "    elif start_day > last_day:\n",
    "        return None\n",
    "    available_days = np.arange(start=start_day, stop=last_day + 1)\n",
    "    weights = np.copy(available_days)\n",
    "    weights = weights / np.sum(weights)\n",
    "    weights = expon.pdf(weights)\n",
    "    weights = weights / np.sum(weights)\n",
    "    return np.random.choice(available_days, size=size, p=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados de Usuário\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos gerar um DataFrame Pandas para conter informações de usuário, assim como o endereço do mesmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Utilizando index do pandas como id\n",
    "users = pd.DataFrame({\n",
    "    'created_at': [],\n",
    "    'birthday': [],\n",
    "    'city': [],\n",
    "    'state': [],\n",
    "    'country': []\n",
    "})\n",
    "display(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando _created_at_ (omitindo _updated_at_ pois ele não aparece em nenhum lugar do relatório)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando distribuição ponderada, priorizando os meses 2, 3 e 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewnorm\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Dia 1 -> 01/01/2023\n",
    "# Dia 2 -> 02/01/2023\n",
    "# ...\n",
    "# Dia 181 -> 30/06/2023\n",
    "# Priorizar meses 2, 3 e 4:\n",
    "# Mês 1: do dia 1 ao 31\n",
    "# Mês 2: do dia 32 ao 59\n",
    "# Mês 3: do dia 60 ao 90\n",
    "# Mês 4: do dia 91 ao 120\n",
    "# Mês 5: do dia 121 ao 151\n",
    "# Mês 6: dia 152 ao 181\n",
    "# Média: dia 76\n",
    "# Desvio padrão: 30\n",
    "# Skewness: 0.5\n",
    "first_day = 1\n",
    "last_day = 181\n",
    "print(f'Primeiro dia: {datetime(2023, 1, 1) + timedelta(days=first_day - 1)}')\n",
    "print(f'Último dia: {datetime(2023, 1, 1) + timedelta(days=last_day - 1)}')\n",
    "available_days = np.arange(first_day, last_day + 1)\n",
    "lin_range = np.linspace(0, 1, last_day - first_day + 1)\n",
    "weights = skewnorm.pdf(x=lin_range, a=3.0, loc=0.3, scale=0.75)\n",
    "# Noise\n",
    "weights = np.abs(weights + np.random.normal(loc=0, scale=0.01, size=last_day - first_day + 1))\n",
    "weights = weights / np.sum(weights)\n",
    "plt.gca().vlines(np.array([32, 122]), ymin=0, ymax=np.max(weights), color='C1')\n",
    "plt.plot(np.arange(first_day, last_day + 1), weights)\n",
    "plt.show()\n",
    "\n",
    "days = np.random.choice(available_days, size=USER_COUNT, p=weights)\n",
    "plt.hist(days, bins=last_day - first_day + 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horas não são aleatórias: priorizar horários de pico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skewnorm\n",
    "\n",
    "\n",
    "def gen_random_minutes(size):\n",
    "    minutes = skewnorm.rvs(a=-0.5, loc=960, scale=240, size=size)\n",
    "    while True:\n",
    "        minutes = np.round(minutes, 0).astype(int)\n",
    "        minutes_outside_interval = np.argwhere(\n",
    "            (minutes < 0) | (minutes >= 1440)).flatten()\n",
    "        if (minutes_outside_interval.size == 0):\n",
    "            break\n",
    "        minutes[minutes_outside_interval] = skewnorm.rvs(\n",
    "            a=-0.5, loc=960, scale=240, size=len(minutes_outside_interval))\n",
    "    return minutes\n",
    "\n",
    "\n",
    "minutes = gen_random_minutes(USER_COUNT)\n",
    "hours = minutes // 60\n",
    "minutes = minutes % 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando created_at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "def _created_at_gen(day, hour, minute):\n",
    "    return (datetime(\n",
    "        2023,\n",
    "        1,\n",
    "        1,\n",
    "        hour,\n",
    "        minute,\n",
    "        np.random.randint(0, 60)) + timedelta(days=int(day - 1))).isoformat()\n",
    "created_at_gen = np.vectorize(_created_at_gen)\n",
    "created_at = created_at_gen(days, hours, minutes)\n",
    "users['created_at'] = created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando datas de nascimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ano será escolhido através de uma distribuição que prioriza fim dos anos 90 e anos 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import alpha\n",
    "\n",
    "available_years = np.arange(2005, 1939, -1)\n",
    "lins = np.linspace(0, 1, len(available_years))\n",
    "weights = alpha.pdf(lins, 3.6, loc=-0.4, scale=2)\n",
    "weights = weights / np.sum(weights)\n",
    "plt.plot(available_years, weights)\n",
    "plt.show()\n",
    "plt.gca().vlines([1990, 1995, 2000, 2005], ymin=0, ymax=np.max(weights), color='C1')\n",
    "plt.gca().hlines(0, xmin=1939, xmax=2005, color='C1')\n",
    "random_years = np.random.choice(available_years, size=USER_COUNT, p=weights)\n",
    "plt.hist(random_years, bins=available_years.size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mês e dia são completamente randômicos, utiliza distribuição uniforme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dates_with_year = np.empty((USER_COUNT,), dtype=object)\n",
    "for i in range(USER_COUNT):\n",
    "    year = random_years[i]\n",
    "    lower_bound = datetime(year, 1, 1)\n",
    "    upper_bound = datetime(year, 12, 31)\n",
    "    random_date = fake.date_between(\n",
    "        start_date=lower_bound, end_date=upper_bound).strftime('%Y-%m-%d')\n",
    "    random_dates_with_year[i] = random_date\n",
    "users['birthday'] = random_dates_with_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenando DataFrame de forma que created_at seja crescente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.sort_values(by='created_at')\n",
    "users = users.reset_index(drop=True)\n",
    "display(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendo índices para cada mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['c_at_month'] = users['created_at'].str.slice(start=5, stop=7).apply(lambda str: int(str))\n",
    "month_intervals = []\n",
    "for i in range(1, 7):\n",
    "    idxs = users.index[users['c_at_month'] == i].tolist()\n",
    "    start_idx = idxs[0]\n",
    "    end_idx = idxs[-1]\n",
    "    month_intervals.append((start_idx, end_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endereços\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos mudar a distribuição de endereços com base na data do onboarding. Portanto, é interessante antes criar uma função que recebe alguns parâmetros, como:\n",
    "\n",
    "- Importância da população para decidir a cidade\n",
    "- Presença de cidades fora do Brasil?\n",
    "- etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cidades do Brasil\n",
    "\n",
    "Utilizando .csv de municipios contidos [aqui](http://blog.mds.gov.br/redesuas/wp-content/uploads/2018/06/Lista_Munic%C3%ADpios_com_IBGE_Brasil_Versao_CSV.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeie o CSV\n",
    "municipios = pd.read_csv('municipios.csv', sep=';')\n",
    "# Ignorando duas colunas\n",
    "municipios = municipios.drop(columns=[\n",
    "    'ConcatUF+Mun',\n",
    "    'Unnamed: 9']).sort_values(by=['População 2010'], ascending=False)\n",
    "# Ignorando munícipios sem informação de população\n",
    "municipios = municipios.dropna(subset=['População 2010'])\n",
    "municipios = municipios.reset_index(drop=True)\n",
    "display(municipios.head(5))\n",
    "# Transformando Presidente Prudente em uma cidade com 2M de habitantes\n",
    "# Só pelo lulz\n",
    "municipios.loc[\n",
    "    municipios['Município'] == 'Presidente Prudente',\n",
    "    'População 2010'\n",
    "  ] = 2000000\n",
    "display(municipios[municipios['Município'] == 'Presidente Prudente'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cidades fora do Brasil\n",
    "\n",
    "Utilizando csv que pode ser encontrado [aqui](https://simplemaps.com/static/data/world-cities/basic/simplemaps_worldcities_basicv1.76.zip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Países da América Latina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latin_america_countries = [\n",
    "    'Argentina',\n",
    "    'Bolivia',\n",
    "    'Chile',\n",
    "    'Colombia',\n",
    "    'Ecuador',\n",
    "    'Paraguay',\n",
    "    'Peru',\n",
    "    'Uruguay'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities = pd.read_csv('worldcities.csv')\n",
    "# Ignorando cidades sem dados populacionais\n",
    "world_cities = world_cities.dropna(subset=['population'])\n",
    "# Incluindo apenas cidades da América Latina (exclui Brasil)\n",
    "world_cities = world_cities[world_cities['country'].isin(latin_america_countries)]\n",
    "# Excluindo cidades com população menor que 500 mil habitantes\n",
    "world_cities = world_cities[world_cities['population'] >= 500000]\n",
    "world_cities = world_cities.reset_index(drop=True)\n",
    "display(world_cities.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, preparando a função\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_cities(size, population_importance=1.6, non_brazilian_percent=0.0):\n",
    "    brazilian_percent = 1.0 - non_brazilian_percent\n",
    "    brazilian_size = int(size * brazilian_percent)\n",
    "    non_brazilian_size = size - brazilian_size\n",
    "    cities = pd.DataFrame(columns=['city', 'state', 'country'])\n",
    "    # Cidades brasileiras\n",
    "    brazilian_cities = pd.DataFrame(columns=['city', 'state', 'country'])\n",
    "    brazilian_population_power = np.power(\n",
    "        municipios['População 2010'], population_importance)\n",
    "    brazilian_population_weights = brazilian_population_power / \\\n",
    "        np.sum(brazilian_population_power)\n",
    "    brazilian_cities_idx = np.random.choice(\n",
    "        municipios.index, p=brazilian_population_weights, size=brazilian_size)\n",
    "    brazilian_cities['city'] = municipios.loc[brazilian_cities_idx,\n",
    "                                              'Município'].values\n",
    "    brazilian_cities['state'] = municipios.loc[brazilian_cities_idx, 'UF'].values\n",
    "    brazilian_cities['country'] = 'Brazil'\n",
    "    # Cidades não brasileiras\n",
    "    non_brazilian_cities = pd.DataFrame(columns=['city', 'state', 'country'])\n",
    "    non_brazilian_population_power = np.power(\n",
    "        world_cities['population'], population_importance)\n",
    "    non_brazilian_population_weights = non_brazilian_population_power / \\\n",
    "        np.sum(non_brazilian_population_power)\n",
    "    non_brazilian_cities_idx = np.random.choice(\n",
    "        world_cities.index, p=non_brazilian_population_weights, size=non_brazilian_size)\n",
    "    non_brazilian_cities['city'] = world_cities.loc[non_brazilian_cities_idx, 'city'].values\n",
    "    non_brazilian_cities['state'] = ''\n",
    "    non_brazilian_cities['country'] = world_cities.loc[non_brazilian_cities_idx, 'country'].values\n",
    "    # Concatenando\n",
    "    cities = pd.concat([brazilian_cities, non_brazilian_cities])\n",
    "    cities = cities.reset_index(drop=True)\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiros 2 meses: focar em capitais do Brasil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = month_intervals[0][0]\n",
    "end_idx = month_intervals[1][1]\n",
    "count = end_idx - start_idx\n",
    "cities = generate_random_cities(count, population_importance=2.5)\n",
    "users.loc[users.index[start_idx: end_idx], [\n",
    "    'city', 'state', 'country']] = cities.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 próximos meses: cidades brasileiras com menor população\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = month_intervals[2][0]\n",
    "end_idx = month_intervals[3][1]\n",
    "count = end_idx - start_idx\n",
    "cities = generate_random_cities(count, population_importance=1.5)\n",
    "users.loc[users.index[start_idx: end_idx], [\n",
    "    'city', 'state', 'country']] = cities.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 últimos meses: cidades no exterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = month_intervals[4][0]\n",
    "end_idx = month_intervals[5][1]\n",
    "count = end_idx - start_idx\n",
    "cities = generate_random_cities(\n",
    "    count, population_importance=1.0, non_brazilian_percent=0.05)\n",
    "users.loc[users.index[start_idx: end_idx], [\n",
    "    'city', 'state', 'country']] = cities.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(users['country'].value_counts())\n",
    "display(users['state'].value_counts())\n",
    "display(users['city'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando dados de usuário em CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def age_from_birthday(birthday_str):\n",
    "    birthday = datetime.fromisoformat(birthday_str)\n",
    "    difference = datetime.now() - birthday\n",
    "    age = difference.days // 365\n",
    "    return age\n",
    "\n",
    "\n",
    "users['age'] = users['birthday'].apply(age_from_birthday)\n",
    "display(users)\n",
    "users.drop('c_at_month', axis=1).to_csv('users.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferências\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que gera transferências com determinada distribuição de valores e horas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transfers(\n",
    "        user_ids,\n",
    "        transfer_quantity,\n",
    "        loc=50,\n",
    "        scale=25,\n",
    "        num_outliers=0\n",
    "    ):\n",
    "    transfers = pd.DataFrame(\n",
    "        columns=[\n",
    "            'id_from',\n",
    "            'id_to',\n",
    "            'hour',\n",
    "            'minute',\n",
    "            'scheduled_date',\n",
    "            'value',\n",
    "            'status'\n",
    "        ]\n",
    "    )\n",
    "    ids_from, ids_to = user_ids\n",
    "    total_size = transfer_quantity\n",
    "    values = np.random.normal(\n",
    "        loc=loc,\n",
    "        scale=scale,\n",
    "        size=total_size - num_outliers\n",
    "    )\n",
    "    values = np.append(values, np.random.normal(\n",
    "            loc=loc*10,\n",
    "            scale=loc*10,\n",
    "            size=num_outliers\n",
    "        )\n",
    "    )\n",
    "    values = np.abs(values)\n",
    "    values = np.round(values, 2)\n",
    "    status = np.random.choice(\n",
    "        ['FAILED', 'DONE', 'SCHEDULED'],\n",
    "        p=[0.002, 0.75, 0.248], size=total_size)\n",
    "    # Chose random ids\n",
    "    transfers_ids_from = np.random.choice(ids_from, size=total_size)\n",
    "    transfers_ids_to = np.random.choice(ids_to, size=total_size)\n",
    "    transfers['id_from'] = transfers_ids_from\n",
    "    transfers['id_to'] = transfers_ids_to\n",
    "    transfers['value'] = values\n",
    "    transfers['status'] = status\n",
    "    # Horário das transferências\n",
    "    minutes = gen_random_minutes(total_size)\n",
    "    hours = minutes // 60\n",
    "    minutes = minutes % 60\n",
    "    transfers['hour'] = hours\n",
    "    transfers['minute'] = minutes\n",
    "    return transfers\n",
    "\n",
    "\n",
    "def decide_transfers_dates(transfers: pd.DataFrame):\n",
    "    users_created_at = users[['created_at']]\n",
    "    transfer_with_user_info = transfers\\\n",
    "        .join(users_created_at, on='id_from')\\\n",
    "        .rename(columns={'created_at': 'created_at_x'})\n",
    "    transfer_with_user_info = transfer_with_user_info\\\n",
    "        .join(users_created_at, on='id_to')\\\n",
    "        .rename(columns={'created_at': 'created_at_y'})\n",
    "    transfer_with_user_info['lower_bound'] = transfer_with_user_info\\\n",
    "        .apply(\n",
    "            lambda row: max(\n",
    "                row['created_at_x'],\n",
    "                row['created_at_y']\n",
    "            ),\n",
    "            axis=1\n",
    "    )\n",
    "    transfer_with_user_info = transfer_with_user_info\\\n",
    "        .drop(\n",
    "            ['created_at_x', 'created_at_y'],\n",
    "            axis=1\n",
    "        )\n",
    "    def gen_month_day(hour, minute, lower_bound):\n",
    "        lower_bound = datetime.fromisoformat(lower_bound)\n",
    "        month = np.random.randint(lower_bound.month, 8)\n",
    "        _, last_day = calendar.monthrange(2023, month)\n",
    "        if month == 7:\n",
    "            day = 1\n",
    "        else:\n",
    "            if month > lower_bound.month:\n",
    "                start_day = 1\n",
    "            else:\n",
    "                start_day = lower_bound.day\n",
    "            date = datetime(2023, month, start_day, int(hour), int(minute))\n",
    "            if (date <= lower_bound):\n",
    "                start_day += 1\n",
    "                if start_day > last_day:\n",
    "                    month += 1\n",
    "                    start_day = 1\n",
    "            day = generate_days((2023, month), 1, start_day=start_day)[0]\n",
    "        date = datetime(2023, month, day, hour, minute)\n",
    "        if (date > lower_bound):\n",
    "            return (day, month)\n",
    "    gen_month_day_vectorized = np.vectorize(gen_month_day)\n",
    "    temp = np.array([\n",
    "        transfer_with_user_info['hour'],\n",
    "        transfer_with_user_info['minute'],\n",
    "        transfer_with_user_info['lower_bound']\n",
    "    ])\n",
    "    day, month = gen_month_day_vectorized(*temp)\n",
    "    temp_t = temp.transpose()\n",
    "    temp = np.array([\n",
    "        month,\n",
    "        day,\n",
    "        temp_t[:, 0],\n",
    "        temp_t[:, 1]\n",
    "    ])\n",
    "    def gen_date_time(month, day, hour, minute):\n",
    "        return datetime(\n",
    "            2023,\n",
    "            month,\n",
    "            day,\n",
    "            hour,\n",
    "            minute,\n",
    "            np.random.randint(0, 60)).isoformat()\n",
    "    gen_date_time_vectorized = np.vectorize(gen_date_time)\n",
    "    date_times = gen_date_time_vectorized(*temp)\n",
    "    new_transfers = transfers.copy()\n",
    "    new_transfers.drop(['hour', 'minute'], axis=1, inplace=True)\n",
    "    new_transfers['time'] = date_times\n",
    "    return new_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_info(transfers: pd.DataFrame):\n",
    "    users_info = users[['created_at', 'city', 'state', 'country', 'age']]\n",
    "    transfer_joined = transfers.join(users_info, on='id_from')\n",
    "    transfer_joined = transfer_joined.join(users_info, on='id_to', lsuffix=\"_from\", rsuffix=\"_to\")\n",
    "    return transfer_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuários na faixa de 18-25: valores mais baixos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subpopulation = users['age'].between(18, 25)\n",
    "subpopulation_size = user_subpopulation.count()\n",
    "active_sample_size = int(0.75 * subpopulation_size)\n",
    "active_users_ids = np.random.choice(users[user_subpopulation].index, size=active_sample_size)\n",
    "transfers_amount = 5 * active_sample_size\n",
    "transfers_18_25 = generate_transfers(\n",
    "    (active_users_ids, users.index), transfers_amount, loc=80, scale=50, num_outliers=int(transfers_amount * 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers_18_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers_18_25 = decide_transfers_dates(transfers_18_25)\n",
    "display(transfers_18_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def generate_scheduled_date(status, time):\n",
    "    if status == 'SCHEDULED':\n",
    "        return fake.date_between(\n",
    "            datetime.fromisoformat(time),\n",
    "            datetime(2023, 7, 31))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "generate_scheduled_date_vectorized = np.vectorize(generate_scheduled_date)\n",
    "input_matrix = np.array([\n",
    "    transfers_18_25['status'],\n",
    "    transfers_18_25['time']\n",
    "])\n",
    "scheduled = generate_scheduled_date_vectorized(*input_matrix)\n",
    "transfers_18_25['scheduled_date'] = scheduled\n",
    "display(transfers_18_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = pd.concat([transfers_18_25], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(transfers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuários na faixa de 26-60: valores mais altos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subpopulation = users['age'].between(26, 60)\n",
    "subpopulation_size = user_subpopulation.count()\n",
    "active_sample_size = int(0.87 * subpopulation_size)\n",
    "active_users_ids = np.random.choice(users[user_subpopulation].index, size=active_sample_size)\n",
    "transfers_amount = 5 * active_sample_size\n",
    "transfers_26_60 = generate_transfers(\n",
    "    (active_users_ids, users.index), transfers_amount, loc=500, scale=200, num_outliers=int(transfers_amount * 0.01))\n",
    "transfers_26_60 = decide_transfers_dates(transfers_26_60)\n",
    "generate_scheduled_date_vectorized = np.vectorize(generate_scheduled_date)\n",
    "input_matrix = np.array([\n",
    "    transfers_26_60['status'],\n",
    "    transfers_26_60['time']\n",
    "])\n",
    "scheduled = generate_scheduled_date_vectorized(*input_matrix)\n",
    "transfers_26_60['scheduled_date'] = scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = pd.concat([transfers, transfers_26_60], axis=0)\n",
    "transfers = transfers.reset_index()\n",
    "transfers = transfers.drop('index', axis=1)\n",
    "display(transfers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuários na faixa de 60+: valores mais baixos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subpopulation = users['age'].between(61, 999)\n",
    "subpopulation_size = user_subpopulation.count()\n",
    "active_sample_size = int(0.5 * subpopulation_size)\n",
    "active_users_ids = np.random.choice(users[user_subpopulation].index, size=active_sample_size)\n",
    "transfers_amount = 3 * active_sample_size\n",
    "transfers_61_plus = generate_transfers(\n",
    "    (active_users_ids, users.index), transfers_amount, loc=200, scale=80, num_outliers=int(transfers_amount * 0.001))\n",
    "transfers_61_plus = decide_transfers_dates(transfers_61_plus)\n",
    "generate_scheduled_date_vectorized = np.vectorize(generate_scheduled_date)\n",
    "input_matrix = np.array([\n",
    "    transfers_61_plus['status'],\n",
    "    transfers_61_plus['time']\n",
    "])\n",
    "scheduled = generate_scheduled_date_vectorized(*input_matrix)\n",
    "transfers_61_plus['scheduled_date'] = scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = pd.concat([transfers, transfers_61_plus], axis=0)\n",
    "transfers = transfers.reset_index()\n",
    "transfers = transfers.drop('index', axis=1)\n",
    "display(transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando por `time`\n",
    "transfers = transfers.sort_values(by='time')\n",
    "transfers = transfers.reset_index()\n",
    "transfers = transfers.drop('index', axis=1)\n",
    "display(transfers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo transferências após o dia 20/07/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranfers_time = transfers['time']\n",
    "transfer_time_as_datetime = np.vectorize(datetime.fromisoformat)(tranfers_time)\n",
    "check = np.vectorize(lambda dt: dt > datetime(2023, 7, 20))\n",
    "dropped_idx = np.argwhere(check(transfer_time_as_datetime)).flatten()\n",
    "transfers = transfers.drop(index=dropped_idx)\n",
    "display(transfers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando informação de usuários (evitando join no Looker Studio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = add_user_info(transfers)\n",
    "display(transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transfers = pd.read_csv(\"transfers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers_eights = np.array_split(transfers, 8)\n",
    "for i, df in enumerate(transfers_eights):\n",
    "    df.to_csv(f'transfers_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample (60%)\n",
    "transfers = transfers.sample(frac=0.88)\n",
    "transfers = transfers.reset_index()\n",
    "transfers = transfers.drop(\"index\", axis=1)\n",
    "display(transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers.to_csv(\"transfers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo: login e atividades"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
