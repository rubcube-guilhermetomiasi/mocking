{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constantes: tamanho do Mock e instância do Faker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "USER_COUNT = 105231\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções usadas ao longo do Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerar dia válido dentro de um determinado mês. Prioriza primeiros dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import calendar\n",
    "from scipy.stats import expon\n",
    "\n",
    "def generate_days(\n",
    "        month: tuple[int, int],\n",
    "        size: int,\n",
    "        start_day: int=1\n",
    "    ) -> np.ndarray | None:\n",
    "    _, last_day = calendar.monthrange(*month)\n",
    "    if start_day == last_day:\n",
    "        return np.full((size,), start_day)\n",
    "    elif start_day > last_day:\n",
    "        return None\n",
    "    available_days = np.arange(start=start_day, stop=last_day + 1)\n",
    "    weights = np.copy(available_days)\n",
    "    weights = weights / np.sum(weights)\n",
    "    weights = expon.pdf(weights)\n",
    "    weights = weights / np.sum(weights)\n",
    "    return np.random.choice(available_days, size=size, p=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados de Usuário\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos gerar um DataFrame Pandas para conter informações de usuário, assim como o endereço do mesmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "users = pd.DataFrame({\n",
    "    'id': [fake.uuid4() for _ in range(USER_COUNT)],\n",
    "    'created_at': None,\n",
    "    'birthday': None,\n",
    "    'city': None,\n",
    "    'state': None,\n",
    "    'country': None\n",
    "})\n",
    "display(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando _created_at_ (omitindo _updated_at_ pois ele não aparece em nenhum lugar do relatório)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando distribuição ponderada, priorizando os meses 2, 3 e 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "available_months = np.array([1, 2, 3, 4, 5, 6])\n",
    "weights_months = np.array([1/6, 1/5, 1/5, 1/4, 1/7, 1/5])\n",
    "weights_months = weights_months + \\\n",
    "    np.random.normal(0, 0.0125, size=weights_months.shape)\n",
    "weights_months = weights_months / np.sum(weights_months)\n",
    "months = np.random.choice(available_months, p=weights_months, size=USER_COUNT)\n",
    "month_counts = np.bincount(months)[1:]\n",
    "accumulated_month_counts = np.cumsum(month_counts)\n",
    "plt.hist(months)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando distribuição ponderada, priorizando dias iniciais do mês\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horas não são aleatórias: priorizar horários de pico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skewnorm\n",
    "\n",
    "\n",
    "def gen_random_minutes(size):\n",
    "    minutes = skewnorm.rvs(a=-0.5, loc=960, scale=240, size=size)\n",
    "    while True:\n",
    "        minutes = np.round(minutes, 0).astype(int)\n",
    "        minutes_outside_interval = np.argwhere(\n",
    "            (minutes < 0) | (minutes >= 1440)).flatten()\n",
    "        if (minutes_outside_interval.size == 0):\n",
    "            break\n",
    "        minutes[minutes_outside_interval] = skewnorm.rvs(\n",
    "            a=-0.5, loc=960, scale=240, size=len(minutes_outside_interval))\n",
    "    return minutes\n",
    "\n",
    "\n",
    "minutes = gen_random_minutes(USER_COUNT)\n",
    "hours = minutes // 60\n",
    "minutes = minutes % 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando created_at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "current_idx = 0\n",
    "for month, user_count_month in zip(available_months, month_counts):\n",
    "    random_days = generate_days((2023, month), size=user_count_month)\n",
    "    c_at_array = np.empty((user_count_month,), dtype=object)\n",
    "    for i in range(user_count_month):\n",
    "        c_at_array[i] = datetime(\n",
    "            2023,\n",
    "            month,\n",
    "            random_days[i],\n",
    "            hours[current_idx + i],\n",
    "            minutes[current_idx + i],\n",
    "            np.random.randint(0, 60)\n",
    "        ).isoformat()\n",
    "    pd_idx = users.index[current_idx:current_idx+user_count_month]\n",
    "    users.loc[pd_idx, 'created_at'] = c_at_array\n",
    "    current_idx += user_count_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando datas de nascimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ano será escolhido através de uma distribuição que prioriza fim dos anos 90 e anos 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import skewnorm\n",
    "\n",
    "alpha = -1.7\n",
    "loc = 2000\n",
    "scale = 8\n",
    "random_years = skewnorm.rvs(a=alpha, loc=loc, scale=scale, size=USER_COUNT)\n",
    "while True:\n",
    "    random_years = np.round(random_years, 0).astype(int)\n",
    "    outside_interval = np.argwhere(random_years > 2005).flatten()\n",
    "    if (outside_interval.size == 0):\n",
    "        break\n",
    "    random_years[outside_interval] = skewnorm.rvs(\n",
    "        a=alpha, loc=loc, scale=scale, size=len(outside_interval))\n",
    "# Count the number of users created in each year\n",
    "# Year is x axis, count is y axis\n",
    "minimum_year = np.min(random_years)\n",
    "maximum_year = np.max(random_years)\n",
    "print(f'Ano mínimo: {minimum_year}')\n",
    "print(f'Ano máximo: {maximum_year}')\n",
    "plt.hist(random_years, bins=range(minimum_year, maximum_year))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mês e dia são completamente randômicos, utiliza distribuição uniforme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dates_with_year = np.empty((USER_COUNT,), dtype=object)\n",
    "for i in range(USER_COUNT):\n",
    "    year = random_years[i]\n",
    "    lower_bound = datetime(year, 1, 1)\n",
    "    upper_bound = datetime(year, 12, 31)\n",
    "    random_date = fake.date_between(\n",
    "        start_date=lower_bound, end_date=upper_bound).strftime('%Y-%m-%d')\n",
    "    random_dates_with_year[i] = random_date\n",
    "users['birthday'] = random_dates_with_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenando DataFrame de forma que created_at seja crescente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.sort_values(by='created_at')\n",
    "users = users.reset_index(drop=True)\n",
    "display(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endereços\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos mudar a distribuição de endereços com base na data do onboarding. Portanto, é interessante antes criar uma função que recebe alguns parâmetros, como:\n",
    "\n",
    "- Importância da população para decidir a cidade\n",
    "- Presença de cidades fora do Brasil?\n",
    "- etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cidades do Brasil\n",
    "\n",
    "Utilizando .csv de municipios contidos [aqui](http://blog.mds.gov.br/redesuas/wp-content/uploads/2018/06/Lista_Munic%C3%ADpios_com_IBGE_Brasil_Versao_CSV.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeie o CSV\n",
    "municipios = pd.read_csv('municipios.csv', sep=';')\n",
    "# Ignorando duas colunas\n",
    "municipios = municipios.drop(columns=[\n",
    "    'ConcatUF+Mun',\n",
    "    'Unnamed: 9']).sort_values(by=['População 2010'], ascending=False)\n",
    "# Ignorando munícipios sem informação de população\n",
    "municipios = municipios.dropna(subset=['População 2010'])\n",
    "municipios = municipios.reset_index(drop=True)\n",
    "display(municipios.head(5))\n",
    "# Transformando Presidente Prudente em uma cidade com 2M de habitantes\n",
    "# Só pelo lulz\n",
    "municipios.loc[\n",
    "    municipios['Município'] == 'Presidente Prudente',\n",
    "    'População 2010'\n",
    "  ] = 2000000\n",
    "display(municipios[municipios['Município'] == 'Presidente Prudente'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cidades fora do Brasil\n",
    "\n",
    "Utilizando csv que pode ser encontrado [aqui](https://simplemaps.com/static/data/world-cities/basic/simplemaps_worldcities_basicv1.76.zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities = pd.read_csv('worldcities.csv')\n",
    "# Ignorando cidades sem dados populacionais\n",
    "world_cities = world_cities.dropna(subset=['population'])\n",
    "# Ignorando cidades brasileiras\n",
    "world_cities = world_cities[world_cities['country'] != 'Brazil']\n",
    "world_cities = world_cities.reset_index(drop=True)\n",
    "display(world_cities.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Países da América Latina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latin_america_countries = [\n",
    "    'Argentina',\n",
    "    'Bolivia',\n",
    "    'Chile',\n",
    "    'Colombia',\n",
    "    'Ecuador',\n",
    "    'Paraguay',\n",
    "    'Peru',\n",
    "    'Uruguay'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, preparando a função\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_cities(size, population_importance=1.6, non_brazilian_percent=0.0, latin_america_importance=10.0):\n",
    "    brazilian_percent = 1.0 - non_brazilian_percent\n",
    "    brazilian_size = int(size * brazilian_percent)\n",
    "    non_brazilian_size = size - brazilian_size\n",
    "    cities = pd.DataFrame(columns=['city', 'state', 'country'])\n",
    "    # Cidades brasileiras\n",
    "    brazilian_cities = pd.DataFrame(columns=['city', 'state', 'country'])\n",
    "    brazilian_population_power = np.power(\n",
    "        municipios['População 2010'], population_importance)\n",
    "    brazilian_population_weights = brazilian_population_power / \\\n",
    "        np.sum(brazilian_population_power)\n",
    "    brazilian_cities_idx = np.random.choice(\n",
    "        municipios.index, p=brazilian_population_weights, size=brazilian_size)\n",
    "    brazilian_cities['city'] = municipios.loc[brazilian_cities_idx,\n",
    "                                              'Município'].values\n",
    "    brazilian_cities['state'] = municipios.loc[brazilian_cities_idx, 'UF'].values\n",
    "    brazilian_cities['country'] = 'Brazil'\n",
    "    # Cidades não brasileiras\n",
    "    non_brazilian_cities = pd.DataFrame(columns=['city', 'state', 'country'])\n",
    "    non_brazilian_population_power = np.power(\n",
    "        world_cities['population'], population_importance)\n",
    "    latin_american_countries_idx = world_cities['country'].isin(\n",
    "        latin_america_countries)\n",
    "    non_brazilian_population_power[latin_american_countries_idx] = np.power(\n",
    "        non_brazilian_population_power[latin_american_countries_idx], latin_america_importance)\n",
    "    non_brazilian_population_weights = non_brazilian_population_power / \\\n",
    "        np.sum(non_brazilian_population_power)\n",
    "    non_brazilian_cities_idx = np.random.choice(\n",
    "        world_cities.index, p=non_brazilian_population_weights, size=non_brazilian_size)\n",
    "    non_brazilian_cities['city'] = world_cities.loc[non_brazilian_cities_idx, 'city'].values\n",
    "    non_brazilian_cities['state'] = ''\n",
    "    non_brazilian_cities['country'] = world_cities.loc[non_brazilian_cities_idx, 'country'].values\n",
    "    # Concatenando\n",
    "    cities = pd.concat([brazilian_cities, non_brazilian_cities])\n",
    "    cities = cities.reset_index(drop=True)\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiros 2 meses: focar em capitais do Brasil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "end_idx = accumulated_month_counts[1]\n",
    "count = end_idx - start_idx\n",
    "cities = generate_random_cities(count, population_importance=2.5)\n",
    "users.loc[users.index[start_idx: end_idx], [\n",
    "    'city', 'state', 'country']] = cities.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 próximos meses: cidades brasileiras com menor população\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = accumulated_month_counts[1]\n",
    "end_idx = accumulated_month_counts[3]\n",
    "count = end_idx - start_idx\n",
    "cities = generate_random_cities(count, population_importance=1.5)\n",
    "users.loc[users.index[start_idx: end_idx], [\n",
    "    'city', 'state', 'country']] = cities.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 últimos meses: cidades no exterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = accumulated_month_counts[3]\n",
    "end_idx = accumulated_month_counts[-1]\n",
    "count = end_idx - start_idx\n",
    "cities = generate_random_cities(\n",
    "    count, population_importance=1.0, non_brazilian_percent=0.15, latin_america_importance=4.0)\n",
    "users.loc[users.index[start_idx: end_idx], [\n",
    "    'city', 'state', 'country']] = cities.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(users['country'].value_counts())\n",
    "display(users['state'].value_counts())\n",
    "display(users['city'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando dados de usuário em CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferências\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que gera transferências com determinada distribuição de valores e horas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import calendar\n",
    "\n",
    "\n",
    "def generate_transfers(\n",
    "        user_ids,\n",
    "        transfer_quantity,\n",
    "        loc=50,\n",
    "        scale=25,\n",
    "        num_outliers=0\n",
    "    ):\n",
    "    transfers = pd.DataFrame(\n",
    "        columns=[\n",
    "            'id_from',\n",
    "            'id_to',\n",
    "            'hour',\n",
    "            'minute',\n",
    "            'scheduled_date',\n",
    "            'value',\n",
    "            'status'\n",
    "        ]\n",
    "    )\n",
    "    ids_from, ids_to = user_ids\n",
    "    total_size = transfer_quantity\n",
    "    values = np.random.normal(\n",
    "        loc=loc,\n",
    "        scale=scale,\n",
    "        size=total_size - num_outliers\n",
    "    )\n",
    "    values = np.append(values, np.random.normal(\n",
    "            loc=3000,\n",
    "            scale=1000,\n",
    "            size=num_outliers\n",
    "        )\n",
    "    )\n",
    "    values = np.abs(values)\n",
    "    values = np.round(values, 2)\n",
    "    status = np.random.choice(\n",
    "        ['FAILED', 'DONE', 'SCHEDULED'],\n",
    "        p=[0.001, 0.6, 0.399], size=total_size)\n",
    "    # Chose random ids\n",
    "    transfers_ids_from = np.random.choice(ids_from, size=total_size)\n",
    "    transfers_ids_to = np.random.choice(ids_to, size=total_size)\n",
    "    transfers['id_from'] = transfers_ids_from\n",
    "    transfers['id_to'] = transfers_ids_to\n",
    "    transfers['value'] = values\n",
    "    transfers['status'] = status\n",
    "    # Horário das transferências\n",
    "    minutes = gen_random_minutes(total_size)\n",
    "    hours = minutes // 60\n",
    "    minutes = minutes % 60\n",
    "    transfers['hour'] = hours\n",
    "    transfers['minute'] = minutes\n",
    "    return transfers\n",
    "\n",
    "\n",
    "def decide_transfers_dates(transfers: pd.DataFrame):\n",
    "    users_created_at = users[['id', 'created_at']]\n",
    "    transfer_with_user_info = pd\\\n",
    "        .merge(\n",
    "            transfers,\n",
    "            users_created_at,\n",
    "            left_on='id_from',\n",
    "            right_on='id',\n",
    "            how='inner')\\\n",
    "        .drop('id', axis=1)\n",
    "    transfer_with_user_info = pd\\\n",
    "        .merge(\n",
    "            transfer_with_user_info,\n",
    "            users_created_at,\n",
    "            left_on='id_to',\n",
    "            right_on='id',\n",
    "            how='inner')\\\n",
    "        .drop('id', axis=1)\n",
    "    transfer_with_user_info['lower_bound'] = transfer_with_user_info\\\n",
    "        .apply(\n",
    "            lambda row: max(\n",
    "                row['created_at_x'],\n",
    "                row['created_at_y']\n",
    "            ),\n",
    "            axis=1\n",
    "    )\n",
    "    transfer_with_user_info = transfer_with_user_info\\\n",
    "        .drop(\n",
    "            ['created_at_x', 'created_at_y'],\n",
    "            axis=1\n",
    "        )\n",
    "    def gen_month_day(hour, minute, lower_bound):\n",
    "        lower_bound = datetime.fromisoformat(lower_bound)\n",
    "        month = np.random.randint(lower_bound.month, 8)\n",
    "        _, last_day = calendar.monthrange(2023, month)\n",
    "        if month == 7:\n",
    "            day = 1\n",
    "        else:\n",
    "            if month > lower_bound.month:\n",
    "                start_day = 1\n",
    "            else:\n",
    "                start_day = lower_bound.day\n",
    "            date = datetime(2023, month, start_day, int(hour), int(minute))\n",
    "            if (date <= lower_bound):\n",
    "                start_day += 1\n",
    "                if start_day > last_day:\n",
    "                    month += 1\n",
    "                    start_day = 1\n",
    "            day = generate_days((2023, month), 1, start_day=start_day)[0]\n",
    "        date = datetime(2023, month, day, hour, minute)\n",
    "        if (date > lower_bound):\n",
    "            return (day, month)\n",
    "    gen_month_day_vectorized = np.vectorize(gen_month_day)\n",
    "    temp = np.array([\n",
    "        transfer_with_user_info['hour'],\n",
    "        transfer_with_user_info['minute'],\n",
    "        transfer_with_user_info['lower_bound']\n",
    "    ])\n",
    "    day, month = gen_month_day_vectorized(*temp)\n",
    "    temp_t = temp.transpose()\n",
    "    temp = np.array([\n",
    "        month,\n",
    "        day,\n",
    "        temp_t[:, 0],\n",
    "        temp_t[:, 1]\n",
    "    ])\n",
    "    def gen_date_time(month, day, hour, minute):\n",
    "        return datetime(\n",
    "            2023,\n",
    "            month,\n",
    "            day,\n",
    "            hour,\n",
    "            minute,\n",
    "            np.random.randint(0, 60)).isoformat()\n",
    "    gen_date_time_vectorized = np.vectorize(gen_date_time)\n",
    "    date_times = gen_date_time_vectorized(*temp)\n",
    "    new_transfers = transfers.copy()\n",
    "    new_transfers.drop(['hour', 'minute'], axis=1, inplace=True)\n",
    "    new_transfers['time'] = date_times\n",
    "    return new_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_from_birthday(birthday_str):\n",
    "    birthday = datetime.fromisoformat(birthday_str)\n",
    "    difference = datetime.now() - birthday\n",
    "    age = difference.days // 365\n",
    "    return age\n",
    "\n",
    "\n",
    "users['age'] = users['birthday'].apply(age_from_birthday)\n",
    "display(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuários na faixa de 18-25: valores mais baixos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subpopulation = users['age'].between(18, 25)\n",
    "subpopulation_size = user_subpopulation.count()\n",
    "active_sample_size = int(0.6 * subpopulation_size)\n",
    "active_users_ids = np.random.choice(users[user_subpopulation]['id'], size=active_sample_size)\n",
    "transfers_amount = 5 * active_sample_size\n",
    "transfers_sample = generate_transfers(\n",
    "    (active_users_ids, users['id']), transfers_amount, loc=80, scale=50, num_outliers=int(transfers_amount * 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers_sample = decide_transfers_dates(transfers_sample)\n",
    "display(transfers_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def generate_scheduled_date(status, time):\n",
    "    if status == 'SCHEDULED':\n",
    "        return fake.date_between(\n",
    "            datetime.fromisoformat(time),\n",
    "            datetime(2023, 7, 31))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "generate_scheduled_date_vectorized = np.vectorize(generate_scheduled_date)\n",
    "input_matrix = np.array([\n",
    "    transfers_sample['status'],\n",
    "    transfers_sample['time']\n",
    "])\n",
    "scheduled = generate_scheduled_date_vectorized(*input_matrix)\n",
    "transfers_sample['scheduled_date'] = scheduled\n",
    "display(transfers_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = pd.concat([transfers_sample], axis=1)\n",
    "transfers = transfers.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuários na faixa de 26-60: valores mais altos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subpopulation = users['age'].between(26, 60)\n",
    "subpopulation_size = user_subpopulation.count()\n",
    "active_sample_size = int(0.6 * subpopulation_size)\n",
    "active_users_ids = np.random.choice(users[user_subpopulation]['id'], size=active_sample_size)\n",
    "transfers_amount = 5 * active_sample_size\n",
    "transfers_sample = generate_transfers(\n",
    "    (active_users_ids, users['id']), transfers_amount, loc=500, scale=200, num_outliers=int(transfers_amount * 0.01))\n",
    "transfers_sample = decide_transfers_dates(transfers_sample)\n",
    "generate_scheduled_date_vectorized = np.vectorize(generate_scheduled_date)\n",
    "input_matrix = np.array([\n",
    "    transfers_sample['status'],\n",
    "    transfers_sample['time']\n",
    "])\n",
    "scheduled = generate_scheduled_date_vectorized(*input_matrix)\n",
    "transfers_sample['scheduled_date'] = scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = pd.concat([transfers, transfers_sample], axis=1)\n",
    "transfers = transfers.reset_index()\n",
    "display(transfers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuários na faixa de 60+: valores mais baixos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subpopulation = users['age'].between(61, 999)\n",
    "subpopulation_size = user_subpopulation.count()\n",
    "active_sample_size = int(0.25 * subpopulation_size)\n",
    "active_users_ids = np.random.choice(users[user_subpopulation]['id'], size=active_sample_size)\n",
    "transfers_amount = 3 * active_sample_size\n",
    "transfers_sample = generate_transfers(\n",
    "    (active_users_ids, users['id']), transfers_amount, loc=200, scale=80, num_outliers=int(transfers_amount * 0.001))\n",
    "transfers_sample = decide_transfers_dates(transfers_sample)\n",
    "generate_scheduled_date_vectorized = np.vectorize(generate_scheduled_date)\n",
    "input_matrix = np.array([\n",
    "    transfers_sample['status'],\n",
    "    transfers_sample['time']\n",
    "])\n",
    "scheduled = generate_scheduled_date_vectorized(*input_matrix)\n",
    "transfers_sample['scheduled_date'] = scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = pd.concat([transfers, transfers_sample], axis=1)\n",
    "transfers = transfers.reset_index()\n",
    "display(transfers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
